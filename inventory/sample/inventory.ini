# This inventory describe a HA typology with stacked etcd (== same nodes as control plane)
# and 3 worker nodes
# See https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.html
# for tips on building your # inventory

# Configure 'ip' variable to bind kubernetes services on a different ip than the default iface
# We should set etcd_member_name for etcd cluster. The node that are not etcd members do not
# need to set the value, or can set the empty string value.

[all]
## kube master nodes
# node1 ansible_host=95.54.0.11  access_ip=10.3.0.1 # ip=10.3.0.1 etcd_member_name=etcd1
# node2 ansible_host=95.54.0.12  access_ip=10.3.0.2 # ip=10.3.0.2 etcd_member_name=etcd2
# node3 ansible_host=95.54.0.13  access_ip=10.3.0.3 # ip=10.3.0.3 etcd_member_name=etcd3

## kube worker nodes
# node4 ansible_host=95.54.0.14  access_ip=10.3.0.4 # ip=10.3.0.4
# node5 ansible_host=95.54.0.15  access_ip=10.3.0.5 # ip=10.3.0.5
# node6 ansible_host=95.54.0.16  access_ip=10.3.0.6 # ip=10.3.0.6
# node7 ansible_host=95.54.0.17  access_ip=10.3.0.7 # ip=10.3.0.7


[k8s_cluster:children]
kube_control_plane
kube_node
# calico_rr


[kube_control_plane]
# node1 etcd_member_name=etcd1
# node2 etcd_member_name=etcd2
# node3 etcd_member_name=etcd3


[etcd:children]
kube_control_plane


# Add nodes to this group to enable Calico network policy
# [calico_rr]
# node3


# If your kube nodes are not isomerous, just add node name instead of group it.
[kube_node:children]
common_cpu_nodes
nvidia_gpu_nodes


[common_cpu_nodes]
node6
node7


[nvidia_gpu_nodes]
node4
node5


## This section demonstrate how to label nodes in defferent inventory groups
# node_labels defined in the this way: {"key1":"value1", "key2":"value2"}
[kube_control_plane:vars]
node_labels={"node-role.kubernetes.io/master":"yes","role":"master"}

[common_cpu_nodes:vars]
node_labels={"node-role.kubernetes.io/worker":"yes","role":"worker","gpu":"no"}

[nvidia_gpu_nodes:vars]
node_labels={"node-role.kubernetes.io/worker":"yes","role":"worker","gpu":"yes"}
